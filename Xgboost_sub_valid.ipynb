{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pandas\n",
    "# !pip install --upgrade google-api-python-client\n",
    "# !pip install --upgrade seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pandas.io import gbq\n",
    "from pandas_gbq import read_gbq\n",
    "import json\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "# from pyspark.sql import functions as sfunc\n",
    "# from pyspark.sql import types as stypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BQ_Connect-FTRL.ipynb\r\n",
      "ftrl_submission.csv\r\n",
      "Kaggle-TalkingData-f0e6b0d0e656.json\r\n",
      "LGBM_99.ipynb\r\n",
      "LGBM_v1.ipynb\r\n",
      "LGBM_v2.ipynb\r\n",
      "sub_lgbm_r_to_python_nocv_150upsample.csv\r\n",
      "sub_lgbm_r_to_python_nocv_170upsample_maxdepth.csv\r\n",
      "sub_lgbm_r_to_python_nocv.csv\r\n",
      "sub_xgb_nocv_150upsample.csv\r\n",
      "test.csv\r\n",
      "train.csv\r\n",
      "Untitled.ipynb\r\n",
      "Valid-data_generation.ipynb\r\n",
      "Wordbatch.ipynb\r\n",
      "XGB_v1.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATE = False\n",
    "\n",
    "MAX_ROUNDS = 250\n",
    "EARLY_STOP = 50\n",
    "OPT_ROUNDS = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load train...\n"
     ]
    }
   ],
   "source": [
    "FULL_OUTFILE = 'xgb_nocv_150upsample_sub.csv'\n",
    "VALID_OUTFILE = 'xgb_withcv_150upsample_valid.csv'\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "import lightgbm as lgb\n",
    "\n",
    "path = ''\n",
    "\n",
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32'\n",
    "        }\n",
    "\n",
    "print('load train...')\n",
    "train_cols = ['ip','app','device','os', 'channel', 'click_time', 'is_attributed']\n",
    "train_df = pd.read_csv(path+\"train.csv\", dtype=dtypes,usecols=train_cols)\n",
    "\n",
    "#train_df = pd.read_csv(path+\"train.csv\", skiprows=range(1,84903891), nrows=100000000,dtype=dtypes, usecols=train_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = '../valid-train_data/'\n",
    "valid_df = pd.read_pickle(path1+'validation.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data prep...\n",
      "Train info before: \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 184903890 entries, 0 to 184903889\n",
      "Data columns (total 7 columns):\n",
      "ip               uint32\n",
      "app              uint16\n",
      "device           uint16\n",
      "os               uint16\n",
      "channel          uint16\n",
      "click_time       object\n",
      "is_attributed    uint8\n",
      "dtypes: object(1), uint16(4), uint32(1), uint8(1)\n",
      "memory usage: 3.6+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 184903890 entries, 0 to 184903889\n",
      "Data columns (total 9 columns):\n",
      "ip               uint32\n",
      "app              uint16\n",
      "device           uint16\n",
      "os               uint16\n",
      "channel          uint16\n",
      "is_attributed    uint8\n",
      "hour             uint8\n",
      "day              uint8\n",
      "in_test_hh       uint8\n",
      "dtypes: uint16(4), uint32(1), uint8(4)\n",
      "memory usage: 2.8 GB\n",
      "None\n",
      "group by : ip_day_test_hh\n",
      "nip_day_test_hh max value =  208661\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 184903890 entries, 0 to 184903889\n",
      "Data columns (total 9 columns):\n",
      "ip                 uint32\n",
      "app                uint16\n",
      "device             uint16\n",
      "os                 uint16\n",
      "channel            uint16\n",
      "is_attributed      uint8\n",
      "hour               uint8\n",
      "day                uint8\n",
      "nip_day_test_hh    uint32\n",
      "dtypes: uint16(4), uint32(2), uint8(3)\n",
      "memory usage: 4.6 GB\n",
      "None\n",
      "group by : ip_day_hh\n",
      "nip_day_hh max value =  44259\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 184903890 entries, 0 to 184903889\n",
      "Data columns (total 10 columns):\n",
      "ip                 uint32\n",
      "app                uint16\n",
      "device             uint16\n",
      "os                 uint16\n",
      "channel            uint16\n",
      "is_attributed      uint8\n",
      "hour               uint8\n",
      "day                uint8\n",
      "nip_day_test_hh    uint32\n",
      "nip_day_hh         uint16\n",
      "dtypes: uint16(5), uint32(2), uint8(3)\n",
      "memory usage: 5.0 GB\n",
      "None\n",
      "group by : ip_hh_os\n",
      "nip_hh_os max value =  9824\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 184903890 entries, 0 to 184903889\n",
      "Data columns (total 11 columns):\n",
      "ip                 uint32\n",
      "app                uint16\n",
      "device             uint16\n",
      "os                 uint16\n",
      "channel            uint16\n",
      "is_attributed      uint8\n",
      "hour               uint8\n",
      "day                uint8\n",
      "nip_day_test_hh    uint32\n",
      "nip_day_hh         uint16\n",
      "nip_hh_os          uint16\n",
      "dtypes: uint16(6), uint32(2), uint8(3)\n",
      "memory usage: 5.3 GB\n",
      "None\n",
      "group by : ip_hh_app\n",
      "nip_hh_app max value =  7592\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 184903890 entries, 0 to 184903889\n",
      "Data columns (total 12 columns):\n",
      "ip                 uint32\n",
      "app                uint16\n",
      "device             uint16\n",
      "os                 uint16\n",
      "channel            uint16\n",
      "is_attributed      uint8\n",
      "hour               uint8\n",
      "day                uint8\n",
      "nip_day_test_hh    uint32\n",
      "nip_day_hh         uint16\n",
      "nip_hh_os          uint16\n",
      "nip_hh_app         uint16\n",
      "dtypes: uint16(7), uint32(2), uint8(3)\n",
      "memory usage: 5.7 GB\n",
      "None\n",
      "group by : ip_hh_dev\n",
      "nip_hh_dev max value =  38190\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 184903890 entries, 0 to 184903889\n",
      "Data columns (total 13 columns):\n",
      "ip                 uint32\n",
      "app                uint16\n",
      "device             uint16\n",
      "os                 uint16\n",
      "channel            uint16\n",
      "is_attributed      uint8\n",
      "hour               uint8\n",
      "day                uint8\n",
      "nip_day_test_hh    uint32\n",
      "nip_day_hh         uint16\n",
      "nip_hh_os          uint16\n",
      "nip_hh_app         uint16\n",
      "nip_hh_dev         uint32\n",
      "dtypes: uint16(7), uint32(3), uint8(3)\n",
      "memory usage: 6.4 GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 184903890 entries, 0 to 184903889\n",
      "Data columns (total 11 columns):\n",
      "app                uint16\n",
      "device             uint16\n",
      "os                 uint16\n",
      "channel            uint16\n",
      "is_attributed      uint8\n",
      "hour               uint8\n",
      "nip_day_test_hh    uint32\n",
      "nip_day_hh         uint16\n",
      "nip_hh_os          uint16\n",
      "nip_hh_app         uint16\n",
      "nip_hh_dev         uint32\n",
      "dtypes: uint16(7), uint32(2), uint8(2)\n",
      "memory usage: 5.5 GB\n",
      "None\n",
      "Train info after: \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 184903890 entries, 0 to 184903889\n",
      "Data columns (total 11 columns):\n",
      "app                uint16\n",
      "device             uint16\n",
      "os                 uint16\n",
      "channel            uint16\n",
      "is_attributed      uint8\n",
      "hour               uint8\n",
      "nip_day_test_hh    uint32\n",
      "nip_day_hh         uint16\n",
      "nip_hh_os          uint16\n",
      "nip_hh_app         uint16\n",
      "nip_hh_dev         uint32\n",
      "dtypes: uint16(7), uint32(2), uint8(2)\n",
      "memory usage: 5.5 GB\n",
      "None\n",
      "vars and data type: \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 184903890 entries, 0 to 184903889\n",
      "Data columns (total 11 columns):\n",
      "app                uint16\n",
      "device             uint16\n",
      "os                 uint16\n",
      "channel            uint16\n",
      "is_attributed      uint8\n",
      "hour               uint8\n",
      "nip_day_test_hh    uint32\n",
      "nip_day_hh         uint16\n",
      "nip_hh_os          uint16\n",
      "nip_hh_app         uint16\n",
      "nip_hh_dev         uint32\n",
      "dtypes: uint16(7), uint32(2), uint8(2)\n",
      "memory usage: 5.5 GB\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "len_train = len(train_df)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print('data prep...')\n",
    "\n",
    "most_freq_hours_in_test_data = [4, 5, 9, 10, 13, 14]\n",
    "least_freq_hours_in_test_data = [6, 11, 15]\n",
    "\n",
    "\n",
    "def prep_data( df ):\n",
    "    \n",
    "    df['hour'] = pd.to_datetime(df.click_time).dt.hour.astype('uint8')\n",
    "    df['day'] = pd.to_datetime(df.click_time).dt.day.astype('uint8')\n",
    "    df.drop(['click_time'], axis=1, inplace=True)\n",
    "    gc.collect()\n",
    "    \n",
    "    df['in_test_hh'] = (   3 \n",
    "                         - 2*df['hour'].isin(  most_freq_hours_in_test_data ) \n",
    "                         - 1*df['hour'].isin( least_freq_hours_in_test_data ) ).astype('uint8')\n",
    "    print( df.info() )\n",
    "\n",
    "    print('group by : ip_day_test_hh')\n",
    "    gp = df[['ip', 'day', 'in_test_hh', 'channel']].groupby(by=['ip', 'day',\n",
    "             'in_test_hh'])[['channel']].count().reset_index().rename(index=str, \n",
    "             columns={'channel': 'nip_day_test_hh'})\n",
    "    df = df.merge(gp, on=['ip','day','in_test_hh'], how='left')\n",
    "    del gp\n",
    "    df.drop(['in_test_hh'], axis=1, inplace=True)\n",
    "    print( \"nip_day_test_hh max value = \", df.nip_day_test_hh.max() )\n",
    "    df['nip_day_test_hh'] = df['nip_day_test_hh'].astype('uint32')\n",
    "    gc.collect()\n",
    "    print( df.info() )\n",
    "\n",
    "    print('group by : ip_day_hh')\n",
    "    gp = df[['ip', 'day', 'hour', 'channel']].groupby(by=['ip', 'day', \n",
    "             'hour'])[['channel']].count().reset_index().rename(index=str, \n",
    "             columns={'channel': 'nip_day_hh'})\n",
    "    df = df.merge(gp, on=['ip','day','hour'], how='left')\n",
    "    del gp\n",
    "    print( \"nip_day_hh max value = \", df.nip_day_hh.max() )\n",
    "    df['nip_day_hh'] = df['nip_day_hh'].astype('uint16')\n",
    "    gc.collect()\n",
    "    print( df.info() )\n",
    "\n",
    "    print('group by : ip_hh_os')\n",
    "    gp = df[['ip', 'day', 'os', 'hour', 'channel']].groupby(by=['ip', 'os', 'day',\n",
    "             'hour'])[['channel']].count().reset_index().rename(index=str, \n",
    "             columns={'channel': 'nip_hh_os'})\n",
    "    df = df.merge(gp, on=['ip','os','hour','day'], how='left')\n",
    "    del gp\n",
    "    print( \"nip_hh_os max value = \", df.nip_hh_os.max() )\n",
    "    df['nip_hh_os'] = df['nip_hh_os'].astype('uint16')\n",
    "    gc.collect()\n",
    "    print( df.info() )\n",
    "\n",
    "    print('group by : ip_hh_app')\n",
    "    gp = df[['ip', 'app', 'hour', 'day', 'channel']].groupby(by=['ip', 'app', 'day',\n",
    "             'hour'])[['channel']].count().reset_index().rename(index=str, \n",
    "             columns={'channel': 'nip_hh_app'})\n",
    "    df = df.merge(gp, on=['ip','app','hour','day'], how='left')\n",
    "    del gp\n",
    "    print( \"nip_hh_app max value = \", df.nip_hh_app.max() )\n",
    "    df['nip_hh_app'] = df['nip_hh_app'].astype('uint16')\n",
    "    gc.collect()\n",
    "    print( df.info() )\n",
    "\n",
    "    print('group by : ip_hh_dev')\n",
    "    gp = df[['ip', 'device', 'hour', 'day', 'channel']].groupby(by=['ip', 'device', 'day',\n",
    "             'hour'])[['channel']].count().reset_index().rename(index=str, \n",
    "             columns={'channel': 'nip_hh_dev'})\n",
    "    df = df.merge(gp, on=['ip','device','day','hour'], how='left')\n",
    "    del gp\n",
    "    print( \"nip_hh_dev max value = \", df.nip_hh_dev.max() )\n",
    "    df['nip_hh_dev'] = df['nip_hh_dev'].astype('uint32')\n",
    "    gc.collect()\n",
    "    print( df.info() )\n",
    "\n",
    "    df.drop( ['ip','day'], axis=1, inplace=True )\n",
    "    gc.collect()\n",
    "    print( df.info() )\n",
    "    \n",
    "    return( df )\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "\n",
    "print( \"Train info before: \")\n",
    "print( train_df.info() )\n",
    "train_df = prep_data( train_df )\n",
    "gc.collect()\n",
    "print( \"Train info after: \")\n",
    "print( train_df.info() )\n",
    "\n",
    "print(\"vars and data type: \")\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   app  device  os  channel  is_attributed  hour  nip_day_test_hh  nip_day_hh  \\\n",
      "0    3       1  13      379              0    14                1           1   \n",
      "1    3       1  19      379              0    14                1           1   \n",
      "2    3       1  13      379              0    14                1           1   \n",
      "3   14       1  13      478              0    14                1           1   \n",
      "4    3       1  13      379              0    14                1           1   \n",
      "\n",
      "   nip_hh_os  nip_hh_app  nip_hh_dev  \n",
      "0          1           1           1  \n",
      "1          1           1           1  \n",
      "2          1           1           1  \n",
      "3          1           1           1  \n",
      "4          1           1           1  \n"
     ]
    }
   ],
   "source": [
    "metrics = 'auc'\n",
    "xgb_params = {'eta': 0.1,\n",
    "          'tree_method': \"hist\",\n",
    "          'grow_policy': \"lossguide\",\n",
    "          'max_leaves': 1400,  \n",
    "          'max_depth': 4, \n",
    "          'subsample': 0.7, \n",
    "          'colsample_bytree': 0.7, \n",
    "          'colsample_bylevel':0.7,\n",
    "          'min_child_weight':0,\n",
    "          'alpha':4,\n",
    "          'objective': 'binary:logistic', \n",
    "          'scale_pos_weight':170,\n",
    "          'eval_metric': 'auc', \n",
    "          'nthread':-1,\n",
    "          'random_state': 99, \n",
    "          'silent': True}\n",
    "\n",
    "target = 'is_attributed'\n",
    "predictors = ['app','device','os', 'channel', 'hour', 'nip_day_test_hh', 'nip_day_hh',\n",
    "              'nip_hh_os', 'nip_hh_app', 'nip_hh_dev']\n",
    "categorical = ['app', 'device', 'os', 'channel', 'hour']\n",
    "\n",
    "print(train_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 184903890 entries, 0 to 184903889\n",
      "Data columns (total 11 columns):\n",
      "app                uint16\n",
      "device             uint16\n",
      "os                 uint16\n",
      "channel            uint16\n",
      "is_attributed      uint8\n",
      "hour               uint8\n",
      "nip_day_test_hh    uint32\n",
      "nip_day_hh         uint16\n",
      "nip_hh_os          uint16\n",
      "nip_hh_app         uint16\n",
      "nip_hh_dev         uint32\n",
      "dtypes: uint16(7), uint32(2), uint8(2)\n",
      "memory usage: 5.5 GB\n",
      "None\n",
      "train size:  184903890\n",
      "Training...\n",
      "[0]\ttrain-auc:0.910955\n",
      "[10]\ttrain-auc:0.95548\n",
      "[20]\ttrain-auc:0.957234\n",
      "[30]\ttrain-auc:0.96179\n",
      "[40]\ttrain-auc:0.964538\n",
      "[50]\ttrain-auc:0.966727\n",
      "[60]\ttrain-auc:0.96793\n",
      "[70]\ttrain-auc:0.969061\n",
      "[80]\ttrain-auc:0.969911\n",
      "[90]\ttrain-auc:0.970625\n",
      "[100]\ttrain-auc:0.971358\n",
      "[110]\ttrain-auc:0.971823\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-47e234dd6ef5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m                     \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m#                    early_stopping_rounds=early_stopping_rounds,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                     verbose_eval=10)\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0moutfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFULL_OUTFILE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 898\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if VALIDATE:\n",
    "\n",
    "    train_df, val_df = train_test_split( train_df, train_size=.95, shuffle=False )\n",
    "\n",
    "    print(train_df.info())\n",
    "    print(val_df.info())\n",
    "\n",
    "    print(\"train size: \", len(train_df))\n",
    "    print(\"valid size: \", len(val_df))\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"Training...\")\n",
    "\n",
    "    num_boost_round=MAX_ROUNDS\n",
    "    early_stopping_rounds=EARLY_STOP\n",
    "\n",
    "    xgtrain = xgb.DMatrix(train_df[predictors].values, label=train_df[target].values)\n",
    "    del train_df\n",
    "    gc.collect()\n",
    "\n",
    "    xgvalid = xgb.DMatrix(val_df[predictors].values, label=val_df[target].values)\n",
    "    del val_df\n",
    "    gc.collect()\n",
    "\n",
    "    evals_results = {}\n",
    "    watchlist = [(xgtrain, 'train'), (xgvalid, 'valid')]\n",
    "    #model = xgb.train(params, dtrain, 200, watchlist, maximize=True, early_stopping_rounds = 25, verbose_eval=5)\n",
    "    \n",
    "    bst = xgb.train(xgb_params, \n",
    "                     xgtrain, \n",
    "                    250,\n",
    "                    watchlist,\n",
    "                    maximize=True,\n",
    "#                     early_stopping_rounds=early_stopping_rounds,\n",
    "                     verbose_eval=10)\n",
    "    \n",
    "    n_estimators = bst.best_iteration\n",
    "\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"n_estimators : \", n_estimators)\n",
    "    print(metrics+\":\", evals_results['valid'][metrics][n_estimators-1])\n",
    "    \n",
    "    outfile = VALID_OUTFILE\n",
    "    \n",
    "    del xgvalid\n",
    "\n",
    "else:\n",
    "\n",
    "    print(train_df.info())\n",
    "\n",
    "    print(\"train size: \", len(train_df))\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"Training...\")\n",
    "\n",
    "    num_boost_round=OPT_ROUNDS\n",
    "\n",
    "    xgtrain = xgb.DMatrix(train_df[predictors].values, label=train_df[target].values)\n",
    "    del train_df\n",
    "    gc.collect()\n",
    "    watchlist = [(xgtrain, 'train')]\n",
    "    bst = xgb.train(xgb_params, \n",
    "                     xgtrain, \n",
    "                    250,\n",
    "                    watchlist,\n",
    "                    maximize=True,\n",
    "#                    early_stopping_rounds=early_stopping_rounds,\n",
    "                    verbose_eval=10)\n",
    "                         \n",
    "    outfile = FULL_OUTFILE\n",
    "    valid_file = VALID_OUTFILE\n",
    "del xgtrain\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('load test...')\n",
    "test_cols = ['ip','app','device','os', 'channel', 'click_time', 'click_id']\n",
    "test_df = pd.read_csv(path+\"test.csv\", dtype=dtypes, usecols=test_cols)\n",
    "\n",
    "test_df = prep_data( test_df )\n",
    "valid_df = prep_data( valid_df )\n",
    "gc.collect()\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['click_id'] = test_df['click_id']\n",
    "\n",
    "print(\"Predicting...\")\n",
    "aa = xgb.DMatrix(test_df[predictors].values)\n",
    "sub['is_attributed'] = bst.predict(aa)\n",
    "sub.head()\n",
    "print(\"writing...\")\n",
    "sub.to_csv(path1+outfile, index=False, float_format='%.9f')\n",
    "print(\"done...\")\n",
    "print(sub.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.DataFrame()\n",
    "bb = xgb.DMatrix(valid_df[predictors].values)\n",
    "val['is_attributed'] = bst.predict(bb)\n",
    "val.to_csv(path1+valid_file, index=False, float_format='%.9f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
