{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from keras.layers import Input, Embedding, Dense, Flatten, Dropout, concatenate\n",
    "from keras.layers import BatchNormalization, SpatialDropout1D, GaussianDropout\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "path = '../input/'\n",
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32'\n",
    "        }\n",
    "print('load train....')\n",
    "# we save only day 9\n",
    "train_df = pd.read_csv(path+\"train.csv\", dtype=dtypes, skiprows = range(1, 131886954), usecols=['ip','app','device','os', 'channel', 'click_time', 'is_attributed'])\n",
    "print('load test....')\n",
    "test_df = pd.read_csv(path+\"test.csv\", dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'click_id'])\n",
    "len_train = len(train_df)\n",
    "train_df=train_df.append(test_df)\n",
    "del test_df; gc.collect()\n",
    "\n",
    "print('hour, day, wday....')\n",
    "train_df['hour'] = pd.to_datetime(train_df.click_time).dt.hour.astype('uint8')\n",
    "train_df['day'] = pd.to_datetime(train_df.click_time).dt.day.astype('uint8')\n",
    "train_df['wday']  = pd.to_datetime(train_df.click_time).dt.dayofweek.astype('uint8')\n",
    "print('grouping by ip alone....')\n",
    "gp = train_df[['ip','channel']].groupby(by=['ip'])[['channel']].count().reset_index().rename(index=str, columns={'channel': 'ipcount'})\n",
    "train_df = train_df.merge(gp, on=['ip'], how='left')\n",
    "del gp; gc.collect()\n",
    "print('grouping by ip-day-hour combination....')\n",
    "gp = train_df[['ip','day','hour','channel']].groupby(by=['ip','day','hour'])[['channel']].count().reset_index().rename(index=str, columns={'channel': 'qty'})\n",
    "train_df = train_df.merge(gp, on=['ip','day','hour'], how='left')\n",
    "del gp; gc.collect()\n",
    "print('group by ip-app combination....')\n",
    "gp = train_df[['ip','app', 'channel']].groupby(by=['ip', 'app'])[['channel']].count().reset_index().rename(index=str, columns={'channel': 'ip_app_count'})\n",
    "train_df = train_df.merge(gp, on=['ip','app'], how='left')\n",
    "del gp; gc.collect()\n",
    "print('group by ip-app-os combination....')\n",
    "gp = train_df[['ip','app', 'os', 'channel']].groupby(by=['ip', 'app', 'os'])[['channel']].count().reset_index().rename(index=str, columns={'channel': 'ip_app_os_count'})\n",
    "train_df = train_df.merge(gp, on=['ip','app', 'os'], how='left')\n",
    "del gp; gc.collect()\n",
    "print(\"vars and data type....\")\n",
    "train_df['ipcount'] = train_df['ipcount'].astype('uint32')\n",
    "train_df['qty'] = train_df['qty'].astype('uint16')\n",
    "train_df['ip_app_count'] = train_df['ip_app_count'].astype('uint16')\n",
    "train_df['ip_app_os_count'] = train_df['ip_app_os_count'].astype('uint16')\n",
    "print(\"label encoding....\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "train_df[['app','device','os', 'channel', 'hour', 'day', 'wday']].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "max_app = train_df['app'].max()+1\n",
    "max_ch = train_df['channel'].max()+1\n",
    "max_dev = train_df['device'].max()+1\n",
    "max_os = train_df['os'].max()+1\n",
    "max_h = train_df['hour'].max()+1\n",
    "max_ipcount = train_df['ipcount'].max()+1\n",
    "max_qty = train_df['qty'].max()+1\n",
    "max_c1 = train_df['ip_app_count'].max()+1\n",
    "max_c2 = train_df['ip_app_os_count'].max()+1\n",
    "\n",
    "train_df['qty_float'] = train_df['qty'].astype('float32') / np.float32(max_qty)\n",
    "train_df['ipcount_float'] = train_df['ipcount'].astype('float32') / np.float32(max_ipcount)\n",
    "train_df['c1_float'] = train_df['ip_app_count'].astype('float32') / np.float32(max_c1)\n",
    "train_df['c2_float'] = train_df['ip_app_os_count'].astype('float32') / np.float32(max_c2)\n",
    "print( train_df.info() )\n",
    "\n",
    "print ('final part of preparation....')\n",
    "test_df = train_df[len_train:]\n",
    "train_df = train_df[:len_train]\n",
    "y_train = train_df['is_attributed'].values\n",
    "tr_ip = train_df['ip']\n",
    "train_df.drop(['click_id', 'click_time','ip','is_attributed'],1,inplace=True)\n",
    "\n",
    "print ('neural network....')\n",
    "\n",
    "def get_keras_data(dataset):\n",
    "    X = {\n",
    "        'app': np.array(dataset.app),\n",
    "        'ch': np.array(dataset.channel),\n",
    "        'dev': np.array(dataset.device),\n",
    "        'os': np.array(dataset.os),\n",
    "        'h': np.array(dataset.hour),\n",
    "        'qty': np.array(dataset.qty),\n",
    "        'ipcount': np.array(dataset.ipcount),\n",
    "        'c1': np.array(dataset.ip_app_count),\n",
    "        'c2': np.array(dataset.ip_app_os_count),\n",
    "        'ipcount_float': np.array(dataset.ipcount_float),\n",
    "        'qty_float': np.array(dataset.qty),\n",
    "        'c1_float': np.array(dataset.c1_float),\n",
    "        'c2_float': np.array(dataset.c2_float)\n",
    "    }\n",
    "    return X\n",
    "train_df = get_keras_data(train_df)\n",
    "\n",
    "print( max_app, max_ch, max_dev, max_os, max_h, max_ipcount, max_qty, max_c1, max_c2 )\n",
    "\n",
    "emb_n = 50\n",
    "dense_n1 = 1000\n",
    "dense_n2 = 1000\n",
    "dense_n3 = 200\n",
    "dense_n4 = 40\n",
    "in_app = Input(shape=[1], name = 'app')\n",
    "emb_app = Embedding(max_app, emb_n)(in_app)\n",
    "in_ch = Input(shape=[1], name = 'ch')\n",
    "emb_ch = Embedding(max_ch, emb_n)(in_ch)\n",
    "in_dev = Input(shape=[1], name = 'dev')\n",
    "emb_dev = Embedding(max_dev, emb_n+30)(in_dev)\n",
    "in_os = Input(shape=[1], name = 'os')\n",
    "emb_os = Embedding(max_os, emb_n)(in_os)\n",
    "in_h = Input(shape=[1], name = 'h')\n",
    "emb_h = Embedding(max_h, emb_n-33)(in_h) \n",
    "in_qty = Input(shape=[1], name = 'qty')\n",
    "emb_qty = Embedding(max_qty, emb_n-10)(in_qty) \n",
    "in_ipcount = Input(shape=[1], name = 'ipcount')\n",
    "emb_ipcount = Embedding(max_ipcount, 2*emb_n+10)(in_ipcount) \n",
    "in_c1 = Input(shape=[1], name = 'c1')\n",
    "emb_c1 = Embedding(max_c1, emb_n-10)(in_c1) \n",
    "in_c2 = Input(shape=[1], name = 'c2')\n",
    "emb_c2 = Embedding(max_c2, emb_n-10)(in_c2)\n",
    "\n",
    "qty_float = Input(shape=[1], dtype='float32', name='qty_float')\n",
    "ipcount_float = Input(shape=[1], dtype='float32', name='ipcount_float')\n",
    "c1_float = Input(shape=[1], dtype='float32', name='c1_float')\n",
    "c2_float = Input(shape=[1], dtype='float32', name='c2_float')\n",
    "\n",
    "fe = concatenate([(emb_app), (emb_ch), (emb_dev), (emb_os), (emb_h), \n",
    "                  (emb_ipcount), (emb_qty), (emb_c1), (emb_c2)])\n",
    "s_dout = SpatialDropout1D(0.2)(fe)\n",
    "x = Flatten()(s_dout)\n",
    "\n",
    "x = concatenate([x, qty_float, ipcount_float, c1_float, c2_float])\n",
    "x = (BatchNormalization())(x)\n",
    "x = GaussianDropout(0.2)(Dense(dense_n1,activation='relu')(x))\n",
    "x = (BatchNormalization())(x)\n",
    "x = GaussianDropout(0.3)(Dense(dense_n2,activation='relu')(x))\n",
    "x = (BatchNormalization())(x)\n",
    "x = GaussianDropout(0.25)(Dense(dense_n3,activation='relu')(x))\n",
    "x = (BatchNormalization())(x)\n",
    "x = GaussianDropout(0.2)(Dense(dense_n4,activation='relu')(x))\n",
    "outp = Dense(1,activation='sigmoid')(x)\n",
    "model = Model(inputs=[in_app, in_ch, in_dev, in_os, in_h, in_ipcount,\n",
    "                      qty_float, ipcount_float, c1_float, c2_float,\n",
    "                      in_qty, in_c1, in_c2], outputs=outp)\n",
    "\n",
    "batch_size = 65536\n",
    "epochs = 10\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "steps = int(len(list(train_df)[0]) / batch_size) * epochs\n",
    "lr_init, lr_fin = 0.0013, 0.0001\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "optimizer_adam = Adam(lr=lr_init, decay=lr_decay)\n",
    "optimizer_adam_nodecay = Adam(lr=lr_init)\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizer_adam_nodecay,metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "class_weight = {0:.01,1:.70} # magic\n",
    "model.fit(train_df, y_train, batch_size=batch_size, epochs=epochs, class_weight=class_weight, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = pd.DataFrame()\n",
    "a = model.predict(train_df, batch_size=batch_size, verbose=2)\n",
    "a = pd.DataFrame(a)\n",
    "a.columns = ['col']\n",
    "valid['is_attributed'] = a['col'].values\n",
    "valid['ip'] = tr_ip\n",
    "del train_df, y_train; gc.collect()\n",
    "model.save_weights('imbalanced_data.h5')\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['click_id'] = test_df['click_id'].astype('int')\n",
    "test_df.drop(['click_id', 'click_time','ip','is_attributed'],1,inplace=True)\n",
    "test_df = get_keras_data(test_df)\n",
    "\n",
    "print(\"predicting....\")\n",
    "sub['is_attributed'] = model.predict(test_df, batch_size=batch_size, verbose=2)\n",
    "del test_df; gc.collect()\n",
    "print(sub.head())\n",
    "print(\"writing....\")\n",
    "sub.to_csv('NNET_sub_10epoch.csv', index=False, float_format='%.9f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32'\n",
    "        }\n",
    "path3 = 'F:/Kaggle/talkingdata-adtracking-fraud-detection/inputs/valid/'\n",
    "val_df = pd.read_csv(path3+\"validation.csv\",dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'is_attributed'])\n",
    "val_ip = val_df['ip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = valid[valid['ip'].isin(val_ip)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.to_csv('NNET_valid_10epoch.csv', index=False, float_format='%.9f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
